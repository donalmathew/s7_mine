
1. split into tokens [[getting_tokens]]


Certainly! Below is the updated code along with a detailed algorithm that outlines the steps taken by the program. The code processes an input file to extract tokens, identifies their types (keywords, operators, special symbols, numbers, and identifiers), and outputs the results.

### Algorithm

1. **Open Files**:
   - Open `input.txt` for reading.
   - Open `intermediate.txt` for writing.

2. **Initialize Buffer**:
   - Create a character array `buffer` to store strings read from the input file.

3. **Read Input File**:
   - While not at the end of the file (`EOF`):
     1. Reset index `i` to 0.
     2. Read a string from `input.txt` into `buffer`.
     3. If the first character of `buffer` is a comment indicator (`/`), skip to the next iteration.
     4. Write a newline character to `intermediate.txt`.
     5. Process each character in `buffer` until the null terminator:
        - If the character is a comment indicator (`/`), break out of the loop.
        - If the character is a special symbol (e.g., `#`, `<`, `>`, `"`, `;`, `(`, `)`, `=`), print it with spaces in `intermediate.txt`.
        - Otherwise, print the character as is.

4. **Close Intermediate File**:
   - Close both input and intermediate files.

5. **Token Classification**:
   - Open `intermediate.txt` for reading and prepare to write to `output.txt`.
   - Initialize a token counter.
   - Define arrays for keywords, operators, and special symbols.
   - While not at the end of the intermediate file:
     1. Read a token into `buffer`.
     2. Increment the token counter.
     3. Check if the token matches any keywords, operators, or special symbols:
        - If it matches a keyword, print it as such.
        - If it matches an operator, print it as such.
        - If it matches a special symbol, print it as such.
        - If it starts with a digit, classify it as a number.
     4. If no matches are found, classify it as an identifier.

6. **Output Total Tokens**:
   - Print the total number of tokens processed.

### C Code

Hereâ€™s the complete code with comments included:

```c
#include<stdio.h>
#include<string.h>
#include<ctype.h>

int main() {
    // 1. Open files
    FILE *inputfp, *interfp, *outputfp;
    inputfp = fopen("input.txt", "r");        // Open input file for reading
    interfp = fopen("intermediate.txt", "w"); // Open intermediate file for writing

    // 2. Initialize buffer to store data
    int i;
    char buffer[1024]; // Buffer to hold strings read from input file

    // 3. Get strings from input file one-by-one
    while (!feof(inputfp)) {
        i = 0; // Reset index for each new string
        fscanf(inputfp, "%s", buffer); // Read a string from input file

        // 3.1 Check for comments (assuming comments start with '/')
        if (buffer[i] == '/') { continue; } // Skip lines starting with '/'

        // 3.3 Jump to newline in output file
        fprintf(interfp, "\n"); // Write a newline in intermediate file

        // 3.2 Print each character from buffer by considering special characters and normal characters separately
        while (buffer[i] != '\0') { // Process each character until end of string

            if (buffer[i] == '/') { break; } // Stop processing if a '/' is encountered

            // Check for special characters and print them with spaces
            if (buffer[i] == '#' || buffer[i] == '<' || buffer[i] == '>' || 
                buffer[i] == '"' || buffer[i] == ';' || buffer[i] == '(' || 
                buffer[i] == ')' || buffer[i] == '=') {
                fprintf(interfp, " %c ", buffer[i]); // Print special character with spaces
            } else {
                fprintf(interfp, "%c", buffer[i]); // Print normal character
            }
            i++; // Move to next character
        }
    }

    // 4. Close the files 
    fclose(inputfp);   // Close input file
    fclose(interfp);   // Close intermediate file

    
// 2nd part starts

    printf("token number    Token       Lexeme");
    interfp = fopen("intermediate.txt", "r"); // Reopen intermediate file for reading
    outputfp = fopen("output.txt", "w");      // Open output file for writing

    int tokencounter = 0;                       // Token counter
    char keywords[30][30] = {"int", "void", "if", "else", "do", "while"}; // List of keywords
    char operators[30][30] = {"+", "-", "*", "/", ">", "<", "=", "%", "&", "|"}; // List of operators
    char splsymbol[30][30] = {";", "{", "}", "(", ")", "?", "!", "@", "#", "."}; // List of special symbols

    int flag = 0;                              // Flag to check if token is recognized
    while (!feof(interfp)) {
        fscanf(interfp, "%s", buffer);       // Read a token from intermediate file

        tokencounter++;                       // Increment token counter

        for (i = 0; i < 30; i++) {
            if (strcmp(buffer, keywords[i]) == 0) {
                printf("\n%d          Keyword          %s", tokencounter, buffer); flag = 1;
            } else if (strcmp(buffer, operators[i]) == 0) {
                printf("\n%d          Operator          %s", tokencounter, buffer); flag = 1;
            } else if (strcmp(buffer, splsymbol[i]) == 0) {
                printf("\n%d          Special Symbol          %s", tokencounter, buffer); flag = 1;
            } else if (isdigit(buffer[0])) {   // Check if first character is a digit
                printf("\n%d          Number          %s", tokencounter, buffer); flag = 1; break;
            }
        }
        
        if (flag == 0) {                     // If no match was found in previous checks
            printf("\n%d          Identifier          %s", tokencounter, buffer);
        } else {
            flag = 0;                        // Reset flag for next token check
        }
    }

    printf("\nTotal number of tokens is: %d\n", tokencounter - 1); // Print total number of tokens excluding last increment

}
```

### Summary

This program effectively reads an input source code file and classifies its contents into various token types while generating an intermediate representation of those tokens. The algorithm provides clarity on how each step is executed within the program's logic.